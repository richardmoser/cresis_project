{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "914384a0570a905a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# TODO:\n",
    "- Add something to add a minimap to the delta_twtt plot to show one point in the general area of the crossover points for quick reference\n",
    "    - or add a plot to the side which displays the continent and a \"you are here\" star marker IVO the crossover points\n",
    "- **Implement multi flight crossover point finding**\n",
    "- average the 2 points on each leg rather than must picking one\n",
    "- select for 45Â° crossovers to see if delta_twtt is ~0\n",
    "- add the Cross class to the class library\n",
    "- revise the code from cross_points down to utilize the Cross class"
   ]
  },
  {
   "cell_type": "code",
   "id": "82c297c4d7d856f2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-08-06T16:51:25.255519Z",
     "start_time": "2024-08-06T16:51:24.216182Z"
    }
   },
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from matplotlib.transforms import ScaledTranslation\n",
    "\n",
    "from project_classes import *\n",
    "from functions import *\n",
    "# from scipy.optimize import curve_fit\n",
    "# import scipy.optimize as opt\n",
    "\n",
    "# %matplotlib notebook \n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "80fa46579d551152",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-08-06T16:51:25.260703Z",
     "start_time": "2024-08-06T16:51:25.256529Z"
    }
   },
   "source": [
    "zoom = True\n",
    "seg_length = 100\n",
    "# season = \"2009_Antarctica_DC8\"\n",
    "season = \"2018_Antarctica_DC8\" \n",
    "season = \"2016_Antarctica_DC8\" \n",
    "# season = \"2014_Antarctica_DC8\" \n",
    "# season = \"2022_Antarctica_BaslerMKB\"\n",
    "\n",
    "# flight = \"20181030_01\"  # the flight date and frame number \n",
    "    # that flight only has one point\n",
    "# flight = \"20181018_01\"\n",
    "# flight = \"20181103_01\"\n",
    "# flight = \"20181011_01\"\n",
    "    # one dimensional data error\n",
    "    # TODO: figure out why 10018 and 1103 have the same data or at least print the same maps and plots\n",
    "# flight = \"20181109_01\"\n",
    "# flight = \"20181112_02\"  # the problem flight\n",
    "    # plots fake crossovers along the curved path\n",
    "# flight = \"20161111_05\"\n",
    "    # probably too close to the coast to be useful\n",
    "flight = \"20161024_05\"\n",
    "flight = \"20161014_05\"\n",
    "    # todo: figure out why there are weird None values for some of the iceflow stuff in this run\n",
    "        # hopefully it is contained to this run\n",
    "\n",
    "# flight = \"20141025_05\"\n",
    "# flight = \"20141026_06\"\n",
    "    # this one is 1/3 of an orbit and produces a bunch of bunk crossovers\n",
    "# flight = \"20230127_01\"\n",
    "    # ~ 1/3 of an orbit of the pole and yet the angle plot looks like hot garbage\n",
    "# flight = \"20230125_01\"\n",
    "# flight = \"20221229_01\"\n",
    "# file_name = \"layer_export_\" + flight + \".pickle\"\n",
    "file_name = f\"pickle_jar\\\\layer_export_{flight}.pickle\"\n",
    "# file_name = \"C:\\\\Users\\\\rj\\\\Desktop\\\\cresis_project\\\\pickle_jar\\\\layer_export_\" + flight + \".pickle\"\n",
    "# file_name = f\"C:\\\\Users\\\\{username}\\\\Desktop\\\\cresis_project\\\\pickle_jar\\\\{season}_{flight}_layers.pickle\"\n",
    "testing = False"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "5e4326b0a8fa5712",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-08-06T16:51:25.407772Z",
     "start_time": "2024-08-06T16:51:25.261711Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "read in the layers from the layer files and save them to a pickle file\n",
    "\"\"\"\n",
    "force = False\n",
    "# force = True\n",
    "whole_season = False\n",
    "# whole_season = True\n",
    "\n",
    "if whole_season:  # if the whole season is being read in\n",
    "    print(type(dir))\n",
    "    file_name = dir + season + \".pickle\"\n",
    "    # print(f\"filename: {filename}\")\n",
    "    if not os.path.isfile(file_name):  # if the file does not exist\n",
    "        debug_print(BRIGHT_RED, f\"File {file_name} does not exist. You should make it...\")\n",
    "    else:\n",
    "        layers = read_layers(file_name)\n",
    "        print(f\"File {file_name} loaded.\")\n",
    "else:  # if only one flight is being read in\n",
    "    if not force:\n",
    "        if not os.path.isfile(file_name):  # if the file does not exist\n",
    "            print(f\"File {file_name} does not exist. Making it...\")\n",
    "            mat_pickler_h5py(season, flight, testing_mode=testing)  # make it\n",
    "            layers = read_layers(file_name)  # read in the layers from the pickle file\n",
    "            print(f\"File {file_name} created.\")\n",
    "        else:\n",
    "            layers = read_layers(file_name)  # read in the layers from the pickle file\n",
    "            print(f\"File {file_name} loaded.\")\n",
    "    else:\n",
    "        mat_pickler_h5py(season, flight, testing_mode=testing)  # make it\n",
    "        layers = read_layers(file_name)  # read in the layers from the pickle file"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File pickle_jar\\layer_export_20161014_05.pickle does not exist. Making it...\n",
      "Reading data files...\n",
      "--------------------\n",
      "\u001B[93mDEBUG: \u001B[92mOpened C:\\Users\\moser\\Documents\\cresis\\rds\\2016_Antarctica_DC8\\CSARP_layer\\20161014_05\\Data_20161014_05_001.mat with h5py\u001B[0m\n",
      "--------------------\n",
      "Reading pickle file...\n",
      "--------------------\n",
      "Surface\n",
      "Bottom\n",
      "--------------------\n",
      "\n",
      "File pickle_jar\\layer_export_20161014_05.pickle created.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "fc35cca7687abf68",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### read in the iceflow data from the iceflow data files and save them to a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "id": "dbaab48f077de2bd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-08-06T16:51:29.146296Z",
     "start_time": "2024-08-06T16:51:25.408779Z"
    }
   },
   "source": [
    "if not os.path.isfile(f\"C:\\\\Users\\\\{username}\\\\Desktop\\\\cresis_project\\\\iceflow\\\\iceflow_data.pickle\"):  # if the file does not exist\n",
    "    print(\"The iceflow data pickle file was not found. Creating a new one...\")\n",
    "    filename = iceflow_saver()\n",
    "    iceflow_data = iceflow_loader(filename)\n",
    "    print(\"The iceflow data pickle file was successfully created.\")\n",
    "# try:\n",
    "iceflow_data = iceflow_loader(\"C:\\\\Users\\\\moser\\\\Desktop\\\\cresis_project\\\\iceflow\\\\iceflow_data.pickle\")\n",
    "print(\"The iceflow data pickle file was found and loaded.\")\n",
    "\n",
    "ice_x = iceflow_data[0]\n",
    "ice_y = iceflow_data[1]\n",
    "# ice_x = iceflow_data[1]\n",
    "# ice_y = iceflow_data[0]\n",
    "ice_velocity_x = iceflow_data[2]\n",
    "ice_velocity_y = iceflow_data[3]\n",
    "ice_latitude = iceflow_data[4]\n",
    "ice_longitude = iceflow_data[5]\n",
    "print(\"iceflow data loaded\")\n",
    "# TODO: 10July24 - are the x and y arrays swapped, is that why things are bunk? Check against QGIS.\n",
    "    # the xy coordinates need to be input backwards to get the right point"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The iceflow data pickle file was found and loaded.\n",
      "iceflow data loaded\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T16:51:29.184013Z",
     "start_time": "2024-08-06T16:51:29.154914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# x_index= 6000\n",
    "x_index = 7500  # column\n",
    "y_index = 6000  # row\n",
    "\n",
    "print(f\"ice_x[{x_index}]: \\t\\t\\t\\t\\t{ice_x[x_index]}, {ice_y[y_index]}\")\n",
    "print(f\"ice_y[{x_index}]]: \\t\\t\\t\\t\\t{ice_y[y_index]}\")\n",
    "print(\"\")\n",
    "print(f\"ice_velocity_x[{y_index}][{x_index}]: \\t{ice_velocity_x[y_index][x_index]}\")\n",
    "print(f\"ice_velocity_y[{y_index}][{x_index}]: \\t{ice_velocity_y[y_index][x_index]}\")\n",
    "print(f\"ice_latitude[{y_index}][{x_index}]: \\t\\t{ice_latitude[y_index][x_index]}\")\n",
    "print(f\"ice_longitude[{y_index}][{x_index}]: \\t\\t{ice_longitude[y_index][x_index]}\")\n",
    "\n",
    "# x_val = index_to_x(x_index)\n",
    "# y_val = index_to_y(y_index)\n",
    "\n",
    "# print(f\"x_val: {x_val}, y_val: {y_val}\")\n"
   ],
   "id": "fb75987ffbe3b81d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ice_x[7500]: \t\t\t\t\t575000.0, 100000.0\n",
      "ice_y[7500]]: \t\t\t\t\t100000.0\n",
      "\n",
      "ice_velocity_x[6000][7500]: \t-2.2737696170806885\n",
      "ice_velocity_y[6000][7500]: \t-1.9776984453201294\n",
      "ice_latitude[6000][7500]: \t\t-84.6322319677139\n",
      "ice_longitude[6000][7500]: \t\t80.13419367766448\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "3eedf3cf8aa71b62",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-08-06T16:51:29.198291Z",
     "start_time": "2024-08-06T16:51:29.185343Z"
    }
   },
   "source": [
    "# if the file at filename exists, read in the intersect_indices and intersection_points from the pickle file\n",
    "# otherwise, find the intersect_indices and intersection_points and save them to a pickle file\n",
    "force_redo_intersections = False\n",
    "# force_redo_intersections = True\n",
    "filename = f\"C:\\\\Users\\\\moser\\\\Desktop\\\\cresis_project\\\\pickle_jar\\\\{season}_{flight}_crossover_points.pickle\"\n",
    "if not os.path.isfile(filename) or force_redo_intersections:  # if the file does not exist\n",
    "    print(f\"File {filename} does not exist. Making it...\")\n",
    "    intersection_points, intersection_indices, segment_ends = cross_point(layers[0], seg_length, quiet=True)\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(intersection_indices, file)\n",
    "        pickle.dump(intersection_points, file)\n",
    "        pickle.dump(segment_ends, file)\n",
    "    print(f\"intersection_indices and intersection_points saved to {filename}\")\n",
    "else:\n",
    "    with open(filename, 'rb') as file:\n",
    "        intersection_indices = pickle.load(file)\n",
    "        intersection_points = pickle.load(file)\n",
    "        segment_ends = pickle.load(file)\n",
    "    print(f\"intersection_indices and intersection_points loaded from {filename}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersection_indices and intersection_points loaded from C:\\Users\\moser\\Desktop\\cresis_project\\pickle_jar\\2016_Antarctica_DC8_20161014_05_crossover_points.pickle\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "9f24c9b6ddf3e87e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T16:51:29.256387Z",
     "start_time": "2024-08-06T16:51:29.200296Z"
    }
   },
   "source": [
    "# TODO: identify why this is still here and not in the functions file\n",
    "    # because it is still being tweaked\n",
    "# TODO: consider normalizing to the elevation, not the surface\n",
    "    # i.e. instead of having the surface be flat, have it represent the actual topology\n",
    "    # really only useful for places where the surface is not basically flat \n",
    "def plot_layers_at_cross(layers, intersection_indices, intersection_points, zoom=False, refractive_index=1.77, cross_index=0, filename=None):\n",
    "    \"\"\"\n",
    "    :param layers: a list of Layer objects\n",
    "    :param intersection_indices: a list of indices in the lat-lon arrays where the flight path\n",
    "    crosses over itself\n",
    "    :param intersection_points: a list of lat-lon points where the flight path crosses over itself\n",
    "    :return: nothing (plots the layers and the map)\n",
    "    \"\"\"\n",
    "    micro = chr(956)\n",
    "    def s_to_ms(x, pos):\n",
    "        \"\"\"\n",
    "        :param x: the x value\n",
    "        :param pos: the position\n",
    "        :return: the x value in milliseconds\n",
    "        \"\"\"\n",
    "        return '%1.2f' % (x * 1e6)\n",
    "\n",
    "    # plt.figure(figsize=(16, 8), layout='constrained')\n",
    "    fig, ax = plt.subplots(figsize=(16, 8), layout='constrained')\n",
    "    # print(\"Plotting layers...\")\n",
    "    # print(\"--------------------\")\n",
    "    # print(\"Adjusting for surface twtt...\")\n",
    "    for layer in layers:\n",
    "        corrected_layer = layer.twtt - layers[0].twtt\n",
    "        layer.twtt_corrected = corrected_layer\n",
    "\n",
    "\n",
    "    # offset = 500\n",
    "    offset = 30\n",
    "    \n",
    "    \"\"\"\n",
    "    with surface normalization\n",
    "    \"\"\"\n",
    "    # ax.plot(\n",
    "    #     layers[1].twtt_corrected[intersection_indices[cross_index][0] - offset:intersection_indices[cross_index][0] + offset],\n",
    "    #     label=layers[1].layer_name + ' segment 1')\n",
    "    # ax.plot(\n",
    "    #     layers[1].twtt_corrected[intersection_indices[cross_index][1] - offset:intersection_indices[cross_index][1] + offset],\n",
    "    #     label=layers[1].layer_name + ' segment 2')\n",
    "\n",
    "    # plot the crossover point on the plot \n",
    "    ax.scatter(offset, layers[1].twtt_corrected[intersection_indices[cross_index][0]], color='red', label='X Point 1')\n",
    "    ax.scatter(offset, layers[1].twtt_corrected[intersection_indices[cross_index][1]], color='green', label='X Point 2')\n",
    "    \n",
    "    \"\"\"\n",
    "    without surface normalization\n",
    "    \"\"\"\n",
    "    # # plot the surface layers\n",
    "    # ax.plot(layers[0].twtt[intersection_indices[cross_index][0] - offset:intersection_indices[cross_index][0] + offset],\n",
    "    #         label=layers[0].layer_name + ' segment 1', linestyle='--')\n",
    "    # ax.plot(layers[0].twtt[intersection_indices[cross_index][1] - offset:intersection_indices[cross_index][1] + offset],\n",
    "    #         label=layers[0].layer_name + ' segment 2', linestyle='--')\n",
    "    \n",
    "    # ax.plot(\n",
    "    #     layers[1].twtt[intersection_indices[cross_index][0] - offset:intersection_indices[cross_index][0] + offset],\n",
    "    #     label=layers[1].layer_name + ' segment 1')\n",
    "    # ax.plot(\n",
    "    #     layers[1].twtt[intersection_indices[cross_index][1] - offset:intersection_indices[cross_index][1] + offset],\n",
    "    #     label=layers[1].layer_name + ' segment 2')\n",
    "    # \n",
    "    # plot the crossover point on the plot \n",
    "    # ax.scatter(offset, layers[1].twtt[intersection_indices[cross_index][0]], color='magenta', label='X Point 1')\n",
    "    # ax.scatter(offset, layers[1].twtt[intersection_indices[cross_index][1]], color='blue', label='X Point 2')\n",
    "    \n",
    "    \n",
    "    n = refractive_index\n",
    "    c = 299792458  # m/s\n",
    "    v = c / n\n",
    "    # depth = twtt * v / 2\n",
    "    scale_factor = v / 2\n",
    "    \n",
    "    # print the twtt at the crossover point on both segments\n",
    "    # twtt = twtt_at_point(layers[1], layers[0], intersection_indices, quiet=)\n",
    "    # twtt = twtt_at_point(layers[1], layers[0], intersection_indices,corrected=True, quiet=True)[cross_index]\n",
    "    twtt = layers[1].twtt_corrected[intersection_indices[cross_index][0]], layers[1].twtt_corrected[intersection_indices[cross_index][1]]\n",
    "    print(f\"twtt: {twtt}\")    \n",
    "\n",
    "    ax.axvline(x=offset, color='black', label='X Point', linestyle='--', linewidth=0.3)\n",
    "    ax.axhline(y=twtt[0], color='red', label='X Point 1', linestyle='--', linewidth=0.3)\n",
    "    ax.axhline(y=twtt[1], color='green', label='X Point 2', linestyle='--', linewidth=0.3)\n",
    "    \n",
    "    # plot a line from twtt[0] to twtt[1] to show the delta twtt\n",
    "    delta_twtt = twtt[1] - twtt[0]\n",
    "    delta_twtt_ms = float(s_to_ms(delta_twtt, None))\n",
    "    ax.plot([offset*0.1, offset*0.1], [twtt[0], twtt[1]], color='black', label='Delta TWTT', linewidth=0.3)\n",
    "    ax.text(offset*0.08, (twtt[0] + twtt[1]) / 2, f\"{delta_twtt_ms:.3f}{micro}s\", fontsize='smaller', ha='right', va='center', color='black')\n",
    "    \n",
    "    # plot a line from twtt[0] to twtt[1] to show the delta twtt in meters\n",
    "    delta_depth = twtt_to_depth(delta_twtt, refractive_index=n)\n",
    "    ax.plot([offset*1.9, offset*1.9], [twtt[0], twtt[1]], color='black', label='Delta Depth', linewidth=0.3)\n",
    "    ax.text(offset*1.92, (twtt[0] + twtt[1]) / 2, f\"{delta_depth:.3f}m\", fontsize='smaller', ha='left', va='center', color='black')\n",
    "    \n",
    "    # plot a horizontal line from (offset - 5) to (offset + 5) to show the distance scale\n",
    "    start = layers[1].twtt_corrected[intersection_indices[cross_index][0] - 5]\n",
    "    end = layers[1].twtt_corrected[intersection_indices[cross_index][0] + 5]\n",
    "    for point in range(intersection_indices[cross_index][0] - 5, intersection_indices[cross_index][0] + 5):\n",
    "        if layers[1].twtt_corrected[point] > start:\n",
    "            start = layers[1].twtt_corrected[point]\n",
    "            # print(f\"start: {start}\")\n",
    "    for point in range(intersection_indices[cross_index][1] - 5, intersection_indices[cross_index][1] + 5):\n",
    "        if layers[1].twtt_corrected[point] > start:\n",
    "            start = layers[1].twtt_corrected[point]\n",
    "            # print(f\"start: {start}\")\n",
    "    # minimum = min(start, end)\n",
    "    minimum = max(start, end)\n",
    "    pixel_offset = 20  # offset 20 pixels\n",
    "    trans = ax.transData + ScaledTranslation(0, -pixel_offset / fig.dpi, ax.figure.dpi_scale_trans)\n",
    "        \n",
    "    ax.plot([offset - 5, offset + 5], [minimum, minimum], transform=trans, color='black', label='Distance Scale', linewidth=0.3)\n",
    "    location1_lat = layers[1].lat[intersection_indices[cross_index][0] - 5]\n",
    "    location1_lon = layers[1].lon[intersection_indices[cross_index][0] - 5]\n",
    "    location2_lat = layers[1].lat[intersection_indices[cross_index][0] + 5]\n",
    "    location2_lon = layers[1].lon[intersection_indices[cross_index][0] + 5]\n",
    "    distance = latlon_dist((location1_lat, location1_lon), (location2_lat, location2_lon))\n",
    "    # ax.text(offset, minimum, f\"{distance:.2f}m\", fontsize='smaller', ha='center', va='top', color='black')\n",
    "    ax.annotate(f\"{distance:.3f}m\", (offset, minimum), xycoords='data', xytext=(0, -5), textcoords='offset points', fontsize='smaller', ha='center', va='top', color='black')\n",
    "        # because the plane is moving so fast, speed is constant â distance is constant â this value will be the same in each plot\n",
    "    \n",
    "    # set the y axis to be in microseconds instead of seconds\n",
    "    plt.ylabel(f\"Adjusted Two Way Travel Time ({micro}s)\")\n",
    "    plt.xlabel(\"Index\")\n",
    "\n",
    "    # force the y values to be displayed in 1e-6 ticks (microseconds) instead of 1e-5 ticks (tens of microseconds)\n",
    "    plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0), useMathText=True)\n",
    "    \n",
    "\n",
    "    # set the y axis to be in microseconds instead of seconds\n",
    "    # plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(s_to_ms))\n",
    "        # set 5 subticks on the y axis\n",
    "    # plt.gca().yaxis.set_minor_locator(plt.MultipleLocator(0.000000005))\n",
    "    # ax.gca().yaxis.set_minor_locator(ax.MultipleLocator(0.5 / 1e6))\n",
    "    plt.legend( fontsize='smaller', loc='lower right')\n",
    "\n",
    "    # make the right side y axis show the depth in meters by converting the twtt to depth using the refractive index\n",
    "    min_y, max_y = plt.ylim()\n",
    "    # n = refractive_index\n",
    "    # c = 299792458  # m/s\n",
    "    # v = c / n\n",
    "    # # depth = twtt * v / 2\n",
    "    # scale_factor = v / 2\n",
    "    # print(f\"scale factor: {scale_factor}\")\n",
    "    # plt.twinx()\n",
    "    # plt.ylim(min_y * scale_factor, max_y * scale_factor)\n",
    "    # plt.ylabel(\"Depth (m)\")\n",
    "    sec_y = ax.twinx()\n",
    "    sec_y.set_ylim(min_y * scale_factor, max_y * scale_factor)\n",
    "    sec_y.set_ylabel(\"Depth (m)\")\n",
    "    sec_y.invert_yaxis()\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "\n",
    "    # make the top of the x axis be the distance in meters by converting the lat-lon to distance using the haversine formula\n",
    "    min_x, max_x = plt.xlim()\n",
    "    scale_factor = latlon_dist((layers[0].lat[0], layers[0].lon[0]), (layers[0].lat[1], layers[0].lon[1]))\n",
    "    # print(f\"scale factor: {scale_factor}\")\n",
    "    # plt.gca().invert_yaxis()\n",
    "\n",
    "    plt.twiny()\n",
    "    plt.xlim(min_x * scale_factor, max_x * scale_factor)\n",
    "    plt.xlabel(\"Distance (m)\")\n",
    "\n",
    "    plt.title(f\"Adjusted Two Way Travel Time vs Index\\n Cross Index {cross_index + 1}\")\n",
    "    \n",
    "    dir = f\"C:\\\\Users\\\\{username}\\\\Desktop\\\\cresis_project\\\\screens\\\\\"\n",
    "    file_name = f\"{season}_{flight}_twtt_vs_index_cross_{cross_index + 1}\"\n",
    "    plt.savefig(f\"{dir}{file_name}.png\", dpi=250)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def bunk_plot(custom_text=None, file_name=None):\n",
    "    \"\"\"\n",
    "    plot a null plot\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(6, 3), layout='constrained')\n",
    "    plt.title(f\"Bunk Plot\")\n",
    "    plt.text(0.5, 0.5, f\"Bunk Plot\", fontsize='32', fontweight='bold', ha='center', va='center', color='black')\n",
    "    if custom_text:\n",
    "        plt.text(0.5, 0.4, custom_text, fontsize='16', fontweight='bold', ha='center', va='center', color='black')\n",
    "    if file_name:\n",
    "        plt.savefig(f\"{file_name}.png\", dpi=250)\n",
    "    plt.show()\n",
    "\n",
    "def plot_map(layers, intersection_indices, intersection_points, iceflow_data, season, flight,  zoom=False, cross_index=0, filename=None):\n",
    "    \"\"\"\n",
    "    plot the map\n",
    "    \"\"\"\n",
    "    plot_it = True\n",
    "    printout = False\n",
    "    \n",
    "    if plot_it:\n",
    "        plt.figure(figsize=(16, 8), layout='constrained')\n",
    "    print(\"Plotting map...\")\n",
    "    # TODO: add an offset to the zoom settings so that the crossover point is in the center of the zoomed in map\n",
    "    offset = 500  # this is not that offset\n",
    "\n",
    "    # this code sets up a polar stereographic map of antarctica with the South Pole in the center\n",
    "    # zoom_out_to_continent = not zoom\n",
    "    zoom_out_to_continent = zoom\n",
    "    if zoom_out_to_continent:\n",
    "        llcrnrx = -400000\n",
    "        llcrnry = -400000\n",
    "        urcrnrx = 250000\n",
    "        urcrnry = 250000\n",
    "    else:\n",
    "        llcrnrx = -300000\n",
    "        llcrnry = -300000\n",
    "        urcrnrx = 300000\n",
    "        urcrnry = 300000\n",
    "    # lat_0 = intersection_points[cross_index][0]\n",
    "    # lon_0 = intersection_points[cross_index][1]\n",
    "    #lat_0 is the average of the latitudes of the crossover points\n",
    "    #lon_0 is the average of the longitudes of the crossover points\n",
    "    lat_0 = sum([point[0] for point in intersection_points]) / len(intersection_points)\n",
    "    lon_0 = sum([point[1] for point in intersection_points]) / len(intersection_points)\n",
    "    \n",
    "    # print(f\"debug: lat_0: {lat_0}, lon_0: {lon_0}\")\n",
    "    if plot_it:\n",
    "        m = Basemap(projection='ortho', lat_0=lat_0, lon_0=lon_0, llcrnrx=llcrnrx, llcrnry=llcrnry, urcrnrx=urcrnrx, urcrnry=urcrnry, resolution='h')\n",
    "        # m = Basemap(projection='spstere', lat_0=-90, lat_ts=-71, lon_0=0, boundinglat=-80, resolution='c')\n",
    "        m.drawcoastlines()\n",
    "        m.fillcontinents(color='grey', lake_color='aqua')\n",
    "        m.drawparallels(np.arange(-80., 81., 20.))\n",
    "        m.drawmeridians(np.arange(-180., 181., 20.))\n",
    "        m.drawmapboundary(fill_color='aqua')\n",
    "    \n",
    "        # plot the flight path\n",
    "        m.plot(layers[0].lon, layers[0].lat, latlon=True, color='lightgreen', linewidth=1)\n",
    "        # plot the section of the flight path in the plot above\n",
    "        m.plot(layers[0].lon[intersection_indices[0][0] - offset:intersection_indices[0][0] + offset],\n",
    "               layers[0].lat[intersection_indices[0][0] - offset:intersection_indices[0][0] + offset], latlon=True,\n",
    "               color='red', linewidth=1)\n",
    "        m.plot(layers[0].lon[intersection_indices[0][1] - offset:intersection_indices[0][1] + offset],\n",
    "               layers[0].lat[intersection_indices[0][1] - offset:intersection_indices[0][1] + offset], latlon=True,\n",
    "               color='green', linewidth=1)\n",
    "        # plot labels for the flight paths at their start points\n",
    "        plt.text(\n",
    "            m(layers[0].lon[intersection_indices[0][0] - offset], layers[0].lat[intersection_indices[0][0] - offset])[0],\n",
    "            m(layers[0].lon[intersection_indices[0][0] - offset], layers[0].lat[intersection_indices[0][0] - offset])[1],\n",
    "            '\\nsegment 1', fontsize='smaller', fontweight='bold', ha='right', va='top', color='red')\n",
    "        plt.text(\n",
    "            m(layers[0].lon[intersection_indices[0][1] - offset], layers[0].lat[intersection_indices[0][1] - offset])[0],\n",
    "            m(layers[0].lon[intersection_indices[0][1] - offset], layers[0].lat[intersection_indices[0][1] - offset])[1],\n",
    "            '\\nsegment 2', fontsize='smaller', fontweight='bold', ha='left', va='top', color='green')\n",
    "        # plot the South Pole\n",
    "        # m.scatter(0, -90, latlon=True, color='black', linewidth=1, label='South Pole')\n",
    "        # plot the crossover points\n",
    "        for point in intersection_points:\n",
    "            m.scatter(point[1], point[0], latlon=True, color='darkred', linewidth=1, label='Crossover Point')\n",
    "            plt.text(m(point[1], point[0])[0], m(point[1], point[0])[1] - 10000, f'{intersection_points.index(point) + 1}\\n\\n',\n",
    "                     fontsize='smaller', fontweight='bold', ha='center', va='top', color='darkred')\n",
    "\n",
    "    # m.scatter(intersection_points[cross_index][1], intersection_points[cross_index][0], latlon=True, color='darkred',\n",
    "    #           linewidth=1, label='Crossover Point')\n",
    "    # plt.text(m(intersection_points[cross_index][1], intersection_points[cross_index][0])[0],\n",
    "    #          m(intersection_points[cross_index][1], intersection_points[cross_index][0])[1] - 10000,\n",
    "    #          'Crossover Point\\n\\n',\n",
    "    #          fontsize='smaller', fontweight='bold', ha='center', va='top', color='darkred')\n",
    "\n",
    "    # plot the the ice flow direction at the crossover point\n",
    "    for i in range(len(intersection_indices)):\n",
    "    # for i in range(1):\n",
    "        cross_lat = intersection_points[i][0]\n",
    "        cross_lon = intersection_points[i][1]\n",
    "        if cross_lon < 0:\n",
    "            cross_lon = 360 + cross_lon\n",
    "        cross_x, cross_y = latlon_to_xy(cross_lat, cross_lon)  \n",
    "        \"\"\"Outputs x and y in EPSG:3031\"\"\"\n",
    "    \n",
    "\n",
    "        \n",
    "        # nearest_x_index, nearest_y_index = xy_to_nearest_unmasked_index(cross_x, cross_y, iceflow_data, max_radius=10)\n",
    "        # nearest_y_index, nearest_x_index = latlon_to_nearest_unmasked_index(cross_lat, cross_lon, iceflow_data, max_radius=10)\n",
    "        nearest_x_index, nearest_y_index = latlon_to_nearest_unmasked_index(cross_lat, cross_lon, iceflow_data, max_radius=10)\n",
    "        \n",
    "        \"\"\"Outputs the nearest x and y indices to the x and y EPSG:3031 values\"\"\"\n",
    "        \n",
    "        \n",
    "        nearest_lat = iceflow_data[4][nearest_y_index][nearest_x_index]  # latitude = iceflow_data[4]\n",
    "        nearest_lon = iceflow_data[5][nearest_y_index][nearest_x_index]  # longitude = iceflow_data[5]\n",
    "        # nearest_lon = - (iceflow_data[5][nearest_x_index][nearest_y_index] - 270)  # longitude = iceflow_data[5]\n",
    "        \n",
    "        # print(f\"nearest_lat: {nearest_lat:.4f}, nearest_lon: {nearest_lon:.4f}\")\n",
    "        \n",
    "\n",
    "        nearest_x, nearest_y = index_to_x(nearest_x_index), index_to_y(nearest_y_index)\n",
    "        \n",
    "    \n",
    "        # flow = flow_at_x_y_index(nearest_x_index, nearest_y_index, iceflow_data)\n",
    "        vx, vy = iceflow_data[2][nearest_y_index][nearest_x_index], iceflow_data[3][nearest_y_index][nearest_x_index]\n",
    "        flow = [vx, vy]\n",
    "        \n",
    "        \n",
    "        flow_heading = xyindex_vector_to_heading(nearest_x_index, nearest_y_index, flow[0], flow[1])[0]\n",
    "        # m.quiver(intersection_points[0][1], intersection_points[0][0], 1000 * np.cos(np.radians(flow_heading)),\n",
    "        #          1000 * np.sin(np.radians(flow_heading)), latlon=True, color='blue', label='Ice Flow Vector')\n",
    "        # plot the ice flow vector in the upper right corner as a quiver\n",
    "        \n",
    "\n",
    "        if printout:\n",
    "            print(f\"cross index: {i+1}\")\n",
    "            print(f\"cross_lat: {cross_lat:.8}, cross_lon: {cross_lon:.8f}\") \n",
    "            print(f\"cross_x: {cross_x:.4f}, cross_y: {cross_y:.4f}\")\n",
    "            print(f\"nearest_x_index: {nearest_x_index}, nearest_y_index: {nearest_y_index}\")\n",
    "            print(f\"nearest_lat: {nearest_lat}, nearest_lon: {nearest_lon}\")\n",
    "            print(f\"nearest_x: {nearest_x:.4f}, nearest_y: {nearest_y:.4f}\")\n",
    "            print(f\"flow at nearest: {flow}\")\n",
    "            print(\"\")\n",
    "            print(f\"Diff x: {(cross_x - nearest_x):.1f}, Diff y: {(cross_y - nearest_y):.1f}\")\n",
    "            print(\"\")\n",
    "            print(section_break)\n",
    "            print(section_break)\n",
    "            print(\"\")\n",
    "        \n",
    "        m.quiver(nearest_x, nearest_y, 10000 * np.cos(np.radians(flow_heading)), 10000 * np.sin(np.radians(flow_heading)), latlon=True, color='blue', label='Ice Flow Vector')\n",
    "        x, y = m(0, -90)\n",
    "    \n",
    "        # plt.text(x, y, '\\nSouth Pole', fontsize='smaller', fontweight='bold', ha='center', va='top', color='black')\n",
    "\n",
    "    # center_x, center_y = latlon_to_xy(intersection_points[cross_index][0], intersection_points[cross_index][1])\n",
    "    center_x, center_y = latlon_to_xy(lat_0, lon_0)\n",
    "    center_x = x_to_index(center_x)\n",
    "    center_y = y_to_index(center_y)\n",
    "    search_range = 750\n",
    "    steps = 50\n",
    "    start_time = time.time()\n",
    "    for x in range(-1 * search_range + center_x, search_range + center_x, steps):\n",
    "        current = x + search_range - center_x    \n",
    "        progress_bar(current,  2 * search_range, start_time)\n",
    "        for y in range(-1 * search_range + center_y, search_range + center_y, steps):\n",
    "            if not (\n",
    "                np.ma.is_masked(iceflow_data[2][y][x]) and np.ma.is_masked(iceflow_data[3][y][x])\n",
    "                ):\n",
    "\n",
    "                vx = 1 * iceflow_data[2][y][x]\n",
    "                vy = 1 * iceflow_data[3][y][x]\n",
    "                flow = [vx, vy]\n",
    "                flow_heading = xyindex_vector_to_heading(x, y, flow[0], flow[1])[0]\n",
    "                scale = 0.0005\n",
    "                mag = np.sqrt(vx**2 + vy**2) * scale\n",
    "                lat = iceflow_data[4][y][x]\n",
    "                lon = iceflow_data[5][y][x]\n",
    "                m.scatter(lon, lat, latlon=True, color='darkred', s=0.75)\n",
    "                # plot a line of length mag in the direction of the flow vector to show the flow vector\n",
    "                endpt = [lon + mag * np.cos(np.radians(flow_heading)), lat + mag * np.sin(np.radians(flow_heading))]\n",
    "                m.plot([lon, endpt[0]], [lat, endpt[1]], latlon=True, color='blue', linewidth=0.5)\n",
    "                \n",
    "            # else:\n",
    "                # print(f\"masked at x: {x}, y: {y}\")\n",
    "        # scatter the south pole\n",
    "        # m.scatter(0, -90, latlon=True, color='white', s=5)\n",
    "        # print(\"\")\n",
    "        \n",
    "    print(\"\")\n",
    "    if plot_it: \n",
    "        plt.title(\"Lat-Lon Map\")\n",
    "        # set tight layout\n",
    "        # plt.tight_layout()\n",
    "    \n",
    "        # save the plot\n",
    "        if filename:\n",
    "            # plt.savefig(f\"{filename}.png\", dpi=250)\n",
    "            dir = \"C:\\\\Users\\\\moser\\\\Desktop\\\\cresis_project\\\\screens\\\\\"\n",
    "            savename = f\"{dir}{filename}_map.png\"\n",
    "            print(f\"saving to {savename}...\")\n",
    "            plt.savefig(savename, dpi=150)\n",
    "        \n",
    "        print(\"drawing to screen...\")\n",
    "        plt.show()\n",
    "\n",
    "    # print(\"plotted map\")\n",
    "    # print(section_break + \"\\n\")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T16:51:29.266268Z",
     "start_time": "2024-08-06T16:51:29.258394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print(segment_ends[0][0][0][0])\n",
    "twtt = twtt_at_point(layers[1], layers[0], intersection_indices, quiet=True)\n",
    "\n",
    "# for i in range(len(segment_ends)):\n",
    "# # for i in range(0,2):\n",
    "#     print(f\"cross {i+1}; i: {i}\")\n",
    "#     # if the twtt at the cross is a nan\n",
    "#     if math.isnan(twtt[i][0]) or math.isnan(twtt[i][1]):\n",
    "#         print(f\"twtt at cross {i+1} is nan\")\n",
    "#         dir = f\"C:\\\\Users\\\\{username}\\\\Desktop\\\\cresis_project\\\\screens\\\\\"\n",
    "#         file_name = f\"{season}_{flight}_twtt_vs_index_cross_{i + 1}\"\n",
    "#         long_name = dir + file_name\n",
    "#         bunk_plot(f\"twtt at cross {i+1} is NaN\", file_name=long_name)\n",
    "#         continue\n",
    "#         \n",
    "#     plot_layers_at_cross(layers, intersection_indices, intersection_points, zoom=zoom, cross_index=i, filename=(season + flight + \"crossover\"))\n",
    "\n",
    "# plot_map(layers, intersection_indices, intersection_points, iceflow_data, season, flight,  zoom=False, cross_index=0, filename=(season + flight + \"crossover\")) "
   ],
   "id": "8eb13f771dbceb73",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- set up separate bottom slope plot and correct bottom slope code\n",
    "    - bottom slope could be represented incorrectly due to surface slope\n",
    "    - the two twtts still need to be normalized to the surface in all other calculations\n",
    "        - the plane to surface distance/twtt could theoretically be different per leg of the flight\n",
    "            - i.e. the plane may have different altitudes at the same location \n",
    "    - <img src=\"layer_plot_notes.png\" height=600>"
   ],
   "id": "ef6720bb3e5f94c0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T16:51:29.277274Z",
     "start_time": "2024-08-06T16:51:29.267272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in layers:\n",
    "        corrected_twtt = layer.twtt - layers[0].twtt  # normalize against the surface layer\n",
    "        # corrected_twtt = layer.twtt\n",
    "        layer.twtt_corrected = corrected_twtt"
   ],
   "id": "2420bbfb2b229258",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T16:51:29.286392Z",
     "start_time": "2024-08-06T16:51:29.282279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print(segment_ends[0])\n",
    "print(segment_ends[0])\n",
    "print()\n",
    "print(segment_ends[0][0][0][0])\n",
    "print(segment_ends[0][0][0][0][0])\n",
    "leg_1 = segment_ends[0][0][0]\n",
    "leg_2 = segment_ends[0][1][0]\n",
    "# print(f\"leg_1: {leg_1}\")\n",
    "# print(f\"leg_2: {leg_2}\")"
   ],
   "id": "2b9e98c3230f09af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[(-72.23647688927026, -69.92573985009878), (-72.23649460470514, -69.92617633223382)], 30937, 30938], [[(-72.23649889621416, -69.92602253178818), (-72.23637201145795, -69.92616790297188)], 120771, 120772]]\n",
      "\n",
      "(-72.23647688927026, -69.92573985009878)\n",
      "-72.23647688927026\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T16:51:30.249425Z",
     "start_time": "2024-08-06T16:51:29.287398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# plot the two legs\n",
    "lat_0 = segment_ends[0][0][0][0][0]\n",
    "lon_0 = segment_ends[0][0][0][0][1]\n",
    "\n",
    "print(f\"lat_0: {lat_0}, lon_0: {lon_0}\")\n",
    "# if lon_0 < 0:\n",
    "    # lon_0 = 360 + lon_0\n",
    "# if lon_0 > 180:\n",
    "    # lon_0 = (lon_0 - 180)\n",
    "print(f\"lat_0: {lat_0}, lon_0: {lon_0}\")\n",
    "\n",
    "# print the first intersection point\n",
    "print(f\"intersection_points[0]: {intersection_points[0]}\")\n",
    "scale = 25\n",
    "llcrnrx = -scale\n",
    "llcrnry = -scale\n",
    "urcrnrx = scale\n",
    "urcrnry = scale\n",
    "offset = 20000\n",
    "\n",
    "print(leg_1[0][0], leg_1[0][1])\n",
    "        \n",
    "m = Basemap(projection='ortho', lat_0=leg_1[0][0], lon_0=leg_1[0][1], llcrnrx=llcrnrx, llcrnry=llcrnry, urcrnrx=urcrnrx, urcrnry=urcrnry, resolution='l')\n",
    "# m = Basemap(projection='spstere', lat_0=-90, lat_ts=-71, lon_0=0, boundinglat=-80, resolution='c')\n",
    "m.drawcoastlines()\n",
    "m.fillcontinents(color='grey', lake_color='aqua')\n",
    "m.drawparallels(np.arange(-80., 81., 20.))\n",
    "m.drawmeridians(np.arange(-180., 181., 20.))\n",
    "\n",
    "debug_print(BRIGHT_MAGENTA, layers[0].lon[intersection_indices[0][0]])\n",
    "\n",
    "# plot the flight path\n",
    "# m.plot(layers[0].lon, layers[0].lat, latlon=True, color='lightgreen', linewidth=1)\n",
    "# plot the section of the flight path in the plot above\n",
    "# m.plot(layers[0].lon[intersection_indices[0][0] - offset:intersection_indices[0][0] + offset],\n",
    "       # layers[0].lat[intersection_indices[0][0] - offset:intersection_indices[0][0] + offset], latlon=True,\n",
    "       # color='green', linewidth=.25)\n",
    "\n",
    "# debug_print(BRIGHT_MAGENTA, leg_2[0], leg_2[0])\n",
    "debug_print(BRIGHT_MAGENTA, leg_2[0][0], leg_2[0][1])\n",
    "\n",
    "# m.scatter(intersection_points[0][0], intersection_points[0][1], color='darkred', linewidth=1, label='Crossover Point')\n",
    "\n",
    "# m.scatter(lon_0, lat_0, latlon=True, color='red', linewidth=0.5, label='Leg 1')\n",
    "m.scatter(leg_2[0][1], leg_2[0][0], latlon=True, color='red', linewidth=1, label='Leg 2')\n",
    "m.scatter(leg_1[1][1], leg_1[1][0], latlon=True, color='green', linewidth=1, label='Leg 1')\n",
    "\n",
    "plt.show()"
   ],
   "id": "2b91cb47d691156b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat_0: -72.23647688927026, lon_0: -69.92573985009878\n",
      "lat_0: -72.23647688927026, lon_0: -69.92573985009878\n",
      "intersection_points[0]: [-72.23647688927026, 290.0742601499012]\n",
      "-72.23647688927026 -69.92573985009878\n",
      "\u001B[93mDEBUG: \u001B[95m-69.92573985009878\u001B[0m\n",
      "\u001B[93mDEBUG: \u001B[95m-72.23649889621416-69.92602253178818\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T16:51:30.255505Z",
     "start_time": "2024-08-06T16:51:30.250434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(len(segment_ends) - 1):\n",
    "    print(i)\n",
    "    print(f\"corrected_twtt[{segment_ends[i][0][1]}]: \\t\\t{corrected_twtt[segment_ends[i][0][1]]}\")\n",
    "    print(f\"corrected_twtt[{segment_ends[i][0][2]}]: \\t\\t{corrected_twtt[segment_ends[i][0][2]]}\")\n",
    "    delta = corrected_twtt[segment_ends[i][0][1]] - corrected_twtt[segment_ends[i][0][2]]\n",
    "    \n",
    "    # print(f\"corrected_twtt[segment_ends[{i}][0][2]]: \\t\\t{corrected_twtt[segment_ends[i][0][2]]}\")\n",
    "    # print(f\"corrected_twtt[segment_ends[{i}][1][2]]: \\t\\t{corrected_twtt[segment_ends[i][1][2]]}\")\n",
    "    # delta = corrected_twtt[segment_ends[i][1][2]] - corrected_twtt[segment_ends[i][0][2]]\n",
    "    print(f\"delta: \\t{delta}\")\n",
    "    print(f\"depth: \\t{twtt_to_depth(delta, refractive_index=1.77)}\")\n",
    "    print(section_break)\n"
   ],
   "id": "947548e8a374c82d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "corrected_twtt[30937]: \t\t5.66273593133962e-06\n",
      "corrected_twtt[30938]: \t\t5.660932007992457e-06\n",
      "delta: \t1.8039233471637254e-09\n",
      "depth: \t0.1527691000818646\n",
      "--------------------\n",
      "1\n",
      "corrected_twtt[40440]: \t\t1.3596298861801616e-05\n",
      "corrected_twtt[40441]: \t\t1.357767209011264e-05\n",
      "delta: \t1.862677168897484e-08\n",
      "depth: \t1.5774479291645704\n",
      "--------------------\n",
      "2\n",
      "corrected_twtt[45800]: \t\t1.3205110993219135e-05\n",
      "corrected_twtt[45801]: \t\t1.322564594934108e-05\n",
      "delta: \t-2.053495612194502e-08\n",
      "depth: \t-1.7390466018983182\n",
      "--------------------\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T16:51:30.264849Z",
     "start_time": "2024-08-06T16:51:30.256514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Cross:\n",
    "    def __init__(self):\n",
    "        self.cross_number = None\n",
    "        self.flow_xy = None\n",
    "        self.flow_v = None\n",
    "        self.intersect_indices = None\n",
    "        \n",
    "        self.leg_1 = None\n",
    "        self.leg_1_ave = None\n",
    "        self.leg_1_indices = None\n",
    "        self.leg_2 = None\n",
    "        self.leg_2_ave = None\n",
    "        self.leg_2_indices = None\n",
    "        self.leg_1_twtt_ave = None\n",
    "        self.leg_2_twtt_ave = None\n",
    "        self.delta_twtt = None\n",
    "        self.leg_1_depth_ave = None\n",
    "        self.leg_2_depth_ave = None\n",
    "        self.depth_ave = None\n",
    "\n",
    "        self.flow_heading_full = None\n",
    "        self.flow_heading = None\n",
    "        self.plane_heading_1 = None\n",
    "        self.plane_heading_2 = None\n",
    "        self.angle = None\n",
    "        # self.twtt = None\n",
    "\n",
    "    \n",
    "    # def to_dict(self):\n",
    "    #     return {\n",
    "        #     'flow_xy': self.flow_xy,\n",
    "        #     'flow_heading_full': self.flow_heading_full,\n",
    "        #     'flow_heading': self.flow_heading,\n",
    "        #     'plane_heading_1': self.plane_heading_1,\n",
    "        #     'plane_heading_2': self.plane_heading_2,\n",
    "        #     'angle': self.angle,\n",
    "        #     'twtt': self.twtt,\n",
    "        #     'delta_twtt': self.delta_twtt,\n",
    "        #     'depth1': self.depth1,\n",
    "        #     'depth2': self.depth2,\n",
    "        #     'depth_ave': self.depth_ave\n",
    "        # }\n",
    "\n",
    "          \n",
    "    def to_dict(self):\n",
    "        return self.__dict__\n",
    "\n",
    "    def __str__(self):\n",
    "        # attributes = self.to_dict()\n",
    "        # str_repr = '\\n'.join(f\"{key}: {value}\" for key, value in attributes.items())\n",
    "        \n",
    "        str_repr = dir(self)\n",
    "        for key in str_repr:\n",
    "            if key[0] != \"_\":\n",
    "                str_repr.pop(key)\n",
    "        \n",
    "        return str_repr\n",
    "\n"
   ],
   "id": "415e746b01a5cb93",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T16:51:30.273289Z",
     "start_time": "2024-08-06T16:51:30.265860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# corrected_twtt[segment_ends[i][0][2]]\n",
    "# corrected_twtt[0]\n",
    "print(segment_ends[0])\n",
    "print()\n",
    "print(segment_ends[0][0][0][1])\n",
    "print(segment_ends[0][0][2])\n",
    "print(corrected_twtt[segment_ends[0][0][2]])\n",
    "print(segment_ends[0][0][0])\n",
    "print(segment_ends[0][1])\n",
    "\n"
   ],
   "id": "c6096bb2ea976e3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[(-72.23647688927026, -69.92573985009878), (-72.23649460470514, -69.92617633223382)], 30937, 30938], [[(-72.23649889621416, -69.92602253178818), (-72.23637201145795, -69.92616790297188)], 120771, 120772]]\n",
      "\n",
      "(-72.23649460470514, -69.92617633223382)\n",
      "30938\n",
      "5.660932007992457e-06\n",
      "[(-72.23647688927026, -69.92573985009878), (-72.23649460470514, -69.92617633223382)]\n",
      "[[(-72.23649889621416, -69.92602253178818), (-72.23637201145795, -69.92616790297188)], 120771, 120772]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T16:51:30.280781Z",
     "start_time": "2024-08-06T16:51:30.274533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(len(intersection_indices)):\n",
    "    # pull the points and indices out of the segment_ends list to make the code more readable\n",
    "    points_leg_1 = segment_ends[0][0][0]  # both end points of the first leg\n",
    "    points_leg_2 = segment_ends[0][1][0]\n",
    "    indices_leg_1 = segment_ends[0][0][1:3]  # both indices of the first leg\n",
    "    indices_leg_2 = segment_ends[0][1][1:3]\n",
    "    \n",
    "    # find the twtts from the indices\n",
    "    leg_1_twtt_1 = corrected_twtt[indices_leg_1[0]]\n",
    "    leg_1_twtt_2 = corrected_twtt[indices_leg_1[1]]\n",
    "    leg_2_twtt_1 = corrected_twtt[indices_leg_2[0]]\n",
    "    leg_2_twtt_2 = corrected_twtt[indices_leg_2[1]]\n",
    "    \n",
    "    # find the average lat and lon of the two legs\n",
    "    leg_1_ave_lat = (points_leg_1[0][0] + points_leg_1[1][0]) / 2\n",
    "    leg_1_ave_lon = (points_leg_1[0][1] + points_leg_1[1][1]) / 2\n",
    "    leg_2_ave_lat = (points_leg_2[0][0] + points_leg_2[1][0]) / 2\n",
    "    leg_2_ave_lon = (points_leg_2[0][1] + points_leg_2[1][1]) / 2\n",
    "    \n",
    "    # find the average twtt of the two legs\n",
    "    leg_1_ave_twtt = (leg_1_twtt_1 + leg_1_twtt_2) / 2\n",
    "    leg_2_ave_twtt = (leg_2_twtt_1 + leg_2_twtt_2) / 2\n",
    "\n",
    "    print(section_break)\n",
    "# TODO: 11Jul24 this is where you stopped. verifying that the averages looked good "
   ],
   "id": "c15adda027e15e53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "--------------------\n",
      "--------------------\n",
      "--------------------\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "b71a3f6174b764a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2024-08-06T16:51:30.714060Z",
     "start_time": "2024-08-06T16:51:30.281787Z"
    }
   },
   "source": [
    "# repeat the above for every crossover point\n",
    "flow_xy = [] # the flow vector in xy \n",
    "flow_heading_full = [] # the flow vector heading in angle1, angle2, distance (in meters)\n",
    "flow_heading = []\n",
    "plane_heading_1 = []\n",
    "plane_heading_2 = []\n",
    "angle = [] # the angle between the flow vector and the plane heading\n",
    "twtt = twtt_at_point(layers[1], layers[0], intersection_indices, quiet=True)\n",
    "delta_twtt = []\n",
    "depth1 = []\n",
    "depth2 = []\n",
    "depth = []\n",
    "\n",
    "cross_points = []\n",
    "\n",
    "for i in range(len(intersection_indices)):\n",
    "    print(f\"intersection {i + 1}\")\n",
    "    point = Cross()\n",
    "    \n",
    "    # pull the points and indices out of the segment_ends list to make the code more readable\n",
    "    points_leg_1 = segment_ends[i][0][0]  # both end points of the first leg\n",
    "    points_leg_2 = segment_ends[i][1][0]\n",
    "    indices_leg_1 = segment_ends[i][0][1:3]  # both indices of the first leg\n",
    "    indices_leg_2 = segment_ends[i][1][1:3]\n",
    "    \n",
    "    # find the twtts from the indices\n",
    "    leg_1_twtt_1 = corrected_twtt[indices_leg_1[0]]\n",
    "    leg_1_twtt_2 = corrected_twtt[indices_leg_1[1]]\n",
    "    leg_2_twtt_1 = corrected_twtt[indices_leg_2[0]]\n",
    "    leg_2_twtt_2 = corrected_twtt[indices_leg_2[1]]\n",
    "    \n",
    "    # find the average lat and lon of the two legs\n",
    "    leg_1_ave_lat = (points_leg_1[0][0] + points_leg_1[1][0]) / 2\n",
    "    leg_1_ave_lon = (points_leg_1[0][1] + points_leg_1[1][1]) / 2\n",
    "    leg_2_ave_lat = (points_leg_2[0][0] + points_leg_2[1][0]) / 2\n",
    "    leg_2_ave_lon = (points_leg_2[0][1] + points_leg_2[1][1]) / 2\n",
    "    \n",
    "    # find the average twtt of the two legs\n",
    "    leg_1_ave_twtt = (leg_1_twtt_1 + leg_1_twtt_2) / 2\n",
    "    leg_2_ave_twtt = (leg_2_twtt_1 + leg_2_twtt_2) / 2\n",
    "    \n",
    "    # assign the values to the point object\n",
    "    point.leg_1 = points_leg_1\n",
    "    point.leg_1_ave = (leg_1_ave_lat, leg_1_ave_lon)\n",
    "    point.leg_2 = points_leg_2\n",
    "    point.leg_2_ave = (leg_2_ave_lat, leg_2_ave_lon)\n",
    "    point.leg_1_twtt_ave = leg_1_ave_twtt\n",
    "    point.leg_2_twtt_ave = leg_2_ave_twtt\n",
    "\n",
    "    point.delta_twtt = abs(leg_1_ave_twtt - leg_2_ave_twtt)\n",
    "    point.leg_1_depth_ave = twtt_to_depth(leg_1_ave_twtt, refractive_index=1.77)\n",
    "    point.leg_2_depth_ave = twtt_to_depth(leg_2_ave_twtt, refractive_index=1.77)\n",
    "    # = twtt_to_depth(leg_1_ave_twtt, refractive_index=1.77)\n",
    "    # point.depth2 = twtt_to_depth(leg_2_ave_twtt, refractive_index=1.77)\n",
    "    point.depth_ave = (point.leg_1_depth_ave + point.leg_2_depth_ave) / 2\n",
    "\n",
    "    \n",
    "    # point.leg_1_ave = leg_1_ave\n",
    "    # point.leg_2 = leg2\n",
    "    # point.leg_2_ave = leg_2_ave\n",
    "    \n",
    "    # convert the lat-lon point to xy and then to indices\n",
    "    lat, lon = intersection_points[i]     \n",
    "    # print(f\"lat: {lat}, lon: {lon}\")\n",
    "    x, y = latlon_to_xy(lat, lon)\n",
    "    # print(f\"x: {x}, y: {y}\")\n",
    "    # x_index, y_index = x_to_index(x), y_to_index(y)\n",
    "    # nearest_x_index, nearest_y_index = xy_to_nearest_unmasked_index(x, y, iceflow_data, max_radius=10)\n",
    "    debug_print(BRIGHT_GREEN, f\"lat: {lat}, lon: {lon}\")\n",
    "    nearest_x_index, nearest_y_index = latlon_to_nearest_unmasked_index(lat, lon, iceflow_data, max_radius=20, printout=True)\n",
    "    if nearest_x_index is None or nearest_y_index is None:\n",
    "        raise ValueError(\"nearest_x_index or nearest_y_index is None\")\n",
    "    print(f\"nearest_x_index: {nearest_x_index}, nearest_y_index: {nearest_y_index}\")\n",
    "    \n",
    "    point.intersect_indices = (indices_leg_1, indices_leg_2)\n",
    "    # debug_print(BRIGHT_GREEN, f\"intersect_indices: {point.intersect_indices}\")\n",
    "    # debug_print(BRIGHT_GREEN, f\"verification: \\t{indices_leg_1}, \\t{indices_leg_2}\")\n",
    "    \n",
    "    nearest_lat = iceflow_data[4][nearest_y_index][nearest_x_index]\n",
    "    nearest_lon = iceflow_data[5][nearest_y_index][nearest_x_index]\n",
    "    # print(f\"nearest_lat: {nearest_lat}, nearest_lon: {nearest_lon}\")\n",
    "\n",
    "\n",
    "    point.flow_xy = [iceflow_data[2][nearest_y_index][nearest_x_index], iceflow_data[3][nearest_y_index][nearest_x_index]]\n",
    "    # print(f\"flow at nearest: {point.flow_xy}\")\n",
    "    \n",
    "    point.flow_v = np.sqrt(point.flow_xy[0]**2 + point.flow_xy[1]**2)\n",
    "    \n",
    "\n",
    "    # print(f\"flow at nearest: {point.flow_xy}\")\n",
    "    \n",
    "    # find the heading of the flow vector   \n",
    "    debug_print(BRIGHT_GREEN, f\"flow at nearest: {point.flow_xy[0]}, {point.flow_xy[1]}\")\n",
    "    point.flow_heading_full = xyindex_vector_to_heading(nearest_x_index, nearest_y_index, point.flow_xy[0], point.flow_xy[1])\n",
    "    \n",
    "    point.flow_heading = point.flow_heading_full[0]\n",
    "    \n",
    "    # print(f\"flow_heading[{i}]: {point.flow_heading}\")\n",
    "    # print(f\"flow_v[{i}]: {point.flow_v}\")\n",
    "    # print(f\"flow_heading_v: {point.flow_heading_full[2]}\")\n",
    "    \n",
    "    # find the heading of the first segment\n",
    "    point.plane_heading_1 = find_heading(layers[0], intersection_indices[i][0])\n",
    "\n",
    "\n",
    "    # find the heading of the second segment\n",
    "    point.plane_heading_2 = find_heading(layers[0], intersection_indices[i][1])\n",
    "    \n",
    "    difference = abs(point.plane_heading_1 - point.plane_heading_2)\n",
    "    if difference > 180:\n",
    "        difference -= 180\n",
    "    other_difference = abs(180 - difference)\n",
    "    # debug_print(BRIGHT_GREEN, f\"\\t\\tplane_heading_1: {point.plane_heading_1}\\n\"\n",
    "    #                           f\"\\t\\t\\tplane_heading_2: {point.plane_heading_2}\\n\"\n",
    "    #                             f\"\\t\\t\\tdifference: {difference} or \"\n",
    "                              # f\"{other_difference}\")  \n",
    "    \n",
    "    \n",
    "    # debug_print(BRIGHT_GREEN, f\"\\t\\tplane_heading_1: {point.plane_heading_1}\\n\"\n",
    "    #                           f\"\\t\\t\\tplane_heading_2: {point.plane_heading_2}\\n\"\n",
    "    #                             f\"\\t\\t\\tdifference: {abs(point.plane_heading_1 - point.plane_heading_2)} or \"\n",
    "    #                           f\"{abs(point.plane_heading_1 - point.plane_heading_2 - 180)}\")\n",
    "    \n",
    "    plane_flow_angle = max(abs(point.plane_heading_1 - point.flow_heading), abs(point.plane_heading_2 - point.flow_heading))\n",
    "\n",
    "    point.angle = plane_flow_angle\n",
    "\n",
    "    # point.delta_twtt = abs(twtt[i][1] - twtt[i][0])\n",
    "    # point.twtt = twtt[i]\n",
    "    # print(f\"twtt[{i}]: {twtt[i]}\")\n",
    "    # point.twtt = twtt[i]\n",
    "    \n",
    "    # point.delta_twtt = (abs(corrected_twtt[intersection_indices[i][1]] - corrected_twtt[intersection_indices[i][0]]))\n",
    "    \n",
    "    point.cross_number = i + 1\n",
    "    \n",
    "    # print(f\"twtt[{i}]: {point.twtt}\n",
    "    # print(f\"twtt[{i}]: {point.twtt[0]:.20f}, {point.twtt[1]:.20f}\")\n",
    "    # print(f\"delta_twtt[{i}]: {point.delta_twtt:.20f}\")\n",
    "    \n",
    "    # print the depth of the crossover point\n",
    "\n",
    "    print(BRIGHT_GREEN, section_break, RESET)        \n",
    "    cross_points.append(point)\n",
    "    \n",
    "# print(cross_points[1])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersection 1\n",
      "\u001B[93mDEBUG: \u001B[92mlat: -72.23647688927026, lon: 290.0742601499012\u001B[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "nearest_x_index or nearest_y_index is None",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 72\u001B[0m\n\u001B[0;32m     70\u001B[0m nearest_x_index, nearest_y_index \u001B[38;5;241m=\u001B[39m latlon_to_nearest_unmasked_index(lat, lon, iceflow_data, max_radius\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20\u001B[39m, printout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m nearest_x_index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m nearest_y_index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 72\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnearest_x_index or nearest_y_index is None\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnearest_x_index: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnearest_x_index\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, nearest_y_index: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnearest_y_index\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     75\u001B[0m point\u001B[38;5;241m.\u001B[39mintersect_indices \u001B[38;5;241m=\u001B[39m (indices_leg_1, indices_leg_2)\n",
      "\u001B[1;31mValueError\u001B[0m: nearest_x_index or nearest_y_index is None"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# print(cross_points[0].__dict__)\n",
    "# dir(cross_points[0])\n",
    "keys = cross_points[0].to_dict().keys()\n",
    "# print(keys)\n",
    "for cross in cross_points:\n",
    "    for key in keys:\n",
    "        # print(f\"{key}: {cross.to_dict()[key]}\")\n",
    "        # if cross.to_dict()[key] is None:\n",
    "        #     print(\"None found\")\n",
    "        #     print(section_break)\n",
    "        if cross.to_dict()[key] is np.nan:\n",
    "            print(\"nan found - numpy\")\n",
    "            print(section_break)\n",
    "        if key == \"twtt\":\n",
    "            if math.isnan(cross.to_dict()[key][0]):\n",
    "                print(\"nan found, cross removed\")\n",
    "                cross_points.remove(cross)\n",
    "                print(section_break)\n",
    "                \n",
    "        "
   ],
   "id": "4d31eb380db2468a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f\"length of cross_points: {len(cross_points)}\")",
   "id": "b81b0d19d2cdb3b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "i = 0\n",
    "length = len(cross_points)\n",
    "while i < length:\n",
    "    delta_heading = abs(cross_points[i].plane_heading_1 - cross_points[i].plane_heading_2)\n",
    "    if delta_heading > 180:\n",
    "        print(f\"subtracted 180 from delta_heading: {delta_heading}\")\n",
    "        delta_heading -= 180\n",
    "    print(f\"delta_heading: {delta_heading}\")\n",
    "    \n",
    "    # if (delta_heading < 75) or (delta_heading > 105):\n",
    "    #     cross_points.remove(cross_points[i])\n",
    "    #     debug_print(BRIGHT_RED, f\"removed index {i} with delta_heading: {delta_heading}\")\n",
    "    #     length -= 1\n",
    "\n",
    "    i += 1\n",
    "print(f\"length of cross_points: {len(cross_points)}\")\n",
    "    \n",
    "    "
   ],
   "id": "1708fa6b5d3ac3e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# i = 0\n",
    "# length = len(cross_points)\n",
    "# while i < length:\n",
    "#     slope1 = average_slope_around_index(layers[0], cross_points[i].intersect_indices[0], 100)\n",
    "#     slope2 = average_slope_around_index(layers[0], cross_points[i].intersect_indices[1], 100)\n",
    "#     # print(f\"slope1: {slope1}, slope2: {slope2}\")\n",
    "#     if slope1 > 0.3 or slope2 > 0.3:\n",
    "#         cross_points.remove(cross_points[i])\n",
    "#         print(f\"removed index {i} with slope1: {slope1}, slope2: {slope2}\")\n",
    "#         length -= 1\n",
    "#     \n",
    "#     i += 1\n",
    "\n",
    "max_d_twtt_ns = 100  \n",
    "max_d_twtt_s = max_d_twtt_ns * 1e-9\n",
    "\n",
    "print(f\"max_d_twtt_ns: {max_d_twtt_ns}\")\n",
    "# print(f\"max_d_twtt_micros: {max_d_twtt_micros}\")\n",
    "\n",
    "print(f\"in ms: {s_to_ms(max_d_twtt_ns, None)}\")\n",
    "\n",
    "for cross in cross_points:\n",
    "    if cross.delta_twtt > max_d_twtt_s:\n",
    "        cross_points.remove(cross)\n",
    "        print(f\"removed cross {cross.cross_number} with delta_twtt: {cross.delta_twtt}\")\n",
    "\n",
    "\n"
   ],
   "id": "1645eaeb401fbaa9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b6399b677fc7842c",
   "metadata": {},
   "source": [
    "# Pressing TODO\n",
    "- point conversion seems to be working so far\n",
    "- need to investigate wht flow headings are varying over small distances\n",
    "    - is this still an issue after 28Jun24?"
   ]
  },
  {
   "cell_type": "code",
   "id": "ac489c22b6e61af4",
   "metadata": {},
   "source": [
    "def generator(n):\n",
    "    \"\"\"\n",
    "    Creates n crosses with random plane and flow angles. twtts are generated based on the angles. The output can be used to find the \"correct/expected\" plot trend\n",
    "\n",
    "    \"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Using just the flow vector and plane heading. Shows the phi in the color of the points.\n",
    "\"\"\"\n",
    "print(f\"length of cross_points: {len(cross_points)}\")\n",
    "micro = False\n",
    "print_time = True\n",
    "\n",
    "plt.figure(figsize=(24, 12), layout='constrained')\n",
    "xdata = []\n",
    "ydata = []\n",
    "zdata = []\n",
    "\n",
    "for i in range(len(cross_points)):\n",
    "    if math.isnan(cross_points[i].delta_twtt):\n",
    "        debug_print(f\"skipping index {i} because delta_twtt is nan\")\n",
    "        continue\n",
    "    theta = cross_points[i].angle  # plane to flow\n",
    "    phi = abs(cross_points[i].plane_heading_1 - cross_points[i].plane_heading_2)  # plane to plane\n",
    "    delta_twtt_micros = cross_points[i].delta_twtt * 1e6\n",
    "    delta_twtt_ns = cross_points[i].delta_twtt * 1e9\n",
    "        \n",
    "    xdata = np.append(xdata, np.abs(np.cos(np.radians(theta))))  # |cos(Î¸)|\n",
    "    # zdata = np.append(zdata, np.abs(np.sin(np.radians(phi))))  # |sin(Ï)|\n",
    "    \n",
    "    # difference = np.abs(phi)\n",
    "    # if difference > 180:\n",
    "    #     difference -= 180\n",
    "    # if difference > 120:\n",
    "    #     difference -= 90\n",
    "    # # other_difference = abs(180 - difference)\n",
    "    # zdata = np.append(zdata, difference)  # |Ï|\n",
    "    \n",
    "    difference = np.abs(phi)\n",
    "    if difference > 0:\n",
    "        next_high = 90\n",
    "        next_low = 0\n",
    "    if difference > 90:\n",
    "        next_high = 180\n",
    "        next_low = 90 \n",
    "    if difference > 180:\n",
    "        next_high = 270\n",
    "        next_low = 180\n",
    "    if difference > 270:\n",
    "        next_high = 360\n",
    "        next_low = 270\n",
    "    difference = min(phi - next_low, next_high - phi)   \n",
    "\n",
    "\n",
    "    zdata = np.append(zdata, difference)  # |Ï|\n",
    "\n",
    "\n",
    "    if micro:    \n",
    "        delta_twtt_unit = delta_twtt_micros  # delta_twtt (Âµs)\n",
    "        if print_time: \n",
    "            print(\"Using microseconds\")\n",
    "            print_time = False\n",
    "    else:\n",
    "        delta_twtt_unit = delta_twtt_ns  # delta_twtt (ns)\n",
    "        if print_time: \n",
    "            print(\"Using nanoseconds\")\n",
    "            print_time = False\n",
    "            \n",
    "    ydata = np.append(ydata, delta_twtt_unit)\n",
    "\n",
    "temp_twtt_s = 0\n",
    "temp_twtt_ns = 0\n",
    "y_label_offset = max(ydata) * .01\n",
    "for i in range(len(xdata)):\n",
    "    if math.isnan(xdata[i]):\n",
    "        debug_print(f\"skipping index {i} because xdata is nan\")\n",
    "        continue\n",
    "    if math.isnan(ydata[i]):\n",
    "        debug_print(f\"skipping index {i} because ydata is nan\")\n",
    "        continue\n",
    "\n",
    "    plt.text(xdata[i], ydata[i] + y_label_offset, f\"cross {cross_points[i].cross_number}\\n{cross_points[i].depth_ave:.1f}m deep\\nÎtwtt {ydata[i]:.2f}ns\", fontsize=10, ha='center', va='bottom')\n",
    "    # degree = zdata[i] * 180 / np.pi\n",
    "    plt.text(xdata[i], ydata[i] - y_label_offset, f\"phi: {zdata[i]:.0f}Â°\", fontsize=10, ha='center', va='top')\n",
    "\n",
    "# Scatter plot with color based on zdata\n",
    "sc = plt.scatter(xdata, ydata, c=zdata, cmap='viridis')\n",
    "\n",
    "# label and show the color bar\n",
    "plt.colorbar(sc, pad=0.01).set_label('\\nphi (degrees) - plane to plane')\n",
    "\n",
    "\n",
    "plt.xlabel(\"|cos(Î¸)| - plane to flow\")\n",
    "plt.title(f\"{season} {flight} \\n|cos(Î¸)| vs delta_twtt\", fontsize=20)\n",
    "\n",
    "plt.ylabel(\"delta_twtt (ns)\")\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.tick_params(which='major', length=10, color='black', width=2)\n",
    "plt.tick_params(which='minor', length=10, color='black', width=1)\n",
    "\n",
    "plt.xlim(-0.1, 1.1)\n",
    "dir = os.getcwd()\n",
    "\n",
    "plt.savefig(f\"{dir}\\\\screens\\\\{season}_{flight}_cos_angle_heading_vs_delta_twtt_logy.png\", dpi=300)\n",
    "\n",
    "\n",
    "plt.yscale('linear')\n",
    "y_min = min(ydata)\n",
    "y_max = max(ydata)\n",
    "zero = 0.000000000000000000000001  # something something floating point error\n",
    "plt.ylim(zero, y_max + y_max*.1)\n",
    "plt.xlim(-0.1, 1.1)\n",
    "plt.savefig(f\"{dir}\\\\screens\\\\{season}_{flight}_cos_angle_heading_vs_delta_twtt_lineary.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"saved plot as {dir}\\\\screens\\\\{season}_{flight}_cos_angle_heading_vs_delta_twtt.png\")"
   ],
   "id": "73112878d61eef9c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TODO: functionize this plot once it works",
   "id": "7bfa0195995f0c97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Delete and start over?\n",
    "\"\"\"\n",
    "\n",
    "micro = False\n",
    "print_time = True\n",
    "\n",
    "plt.figure(figsize=(24, 12), layout='constrained')\n",
    "xdata = []\n",
    "ydata = []\n",
    "\n",
    "for i in range(len(cross_points)):\n",
    "    if math.isnan(cross_points[i].delta_twtt):\n",
    "        debug_print(f\"skipping index {i} because delta_twtt is nan\")\n",
    "        continue\n",
    "    theta = cross_points[i].angle  # plane to flow\n",
    "    phi = abs(cross_points[i].plane_heading_1 - cross_points[i].plane_heading_2)  # plane to plane\n",
    "    delta_twtt_micros = cross_points[i].delta_twtt * 1e6\n",
    "    delta_twtt_ns = cross_points[i].delta_twtt * 1e9\n",
    "        \n",
    "    xdata = np.append(xdata, np.abs(np.cos(np.radians(theta)) - np.sin(np.radians(phi))))  # |cos(Î¸) â sin(Ï)|\n",
    "    \n",
    "    # xdata = np.append(xdata, np.abs(np.cos(np.radians(theta))))  # |cos(Î¸) â sin(Ï)|\n",
    "\n",
    "    \n",
    "    if micro:    \n",
    "        delta_twtt_unit = delta_twtt_micros  # delta_twtt (Âµs)\n",
    "        if print_time: \n",
    "            print(\"Using microseconds\")\n",
    "            print_time = False\n",
    "    else:\n",
    "        delta_twtt_unit = delta_twtt_ns  # delta_twtt (ns)\n",
    "        if print_time: \n",
    "            print(\"Using nanoseconds\")\n",
    "            print_time = False\n",
    "            \n",
    "    ydata = np.append(ydata, delta_twtt_unit)\n",
    "\n",
    "temp_twtt_s = 0\n",
    "temp_twtt_ns = 0\n",
    "y_label_offset = max(ydata) * .01\n",
    "for i in range(len(xdata)):\n",
    "    if math.isnan(xdata[i]):\n",
    "        debug_print(f\"skipping index {i} because xdata is nan\")\n",
    "        continue\n",
    "    if math.isnan(ydata[i]):\n",
    "        debug_print(f\"skipping index {i} because ydata is nan\")\n",
    "        continue\n",
    "    # plt.text(xdata[index], ydata[index] + y_label_offset, f\"Cross {index+1}: {depth[index]:.1f}m\", fontsize=10)\n",
    "    # plt.text(xdata[i], ydata[i] + y_label_offset, f\"Cross {cross_points[i].cross_number}: {cross_points[i].depth1:.1f}m and {cross_points[i].depth2:.1f}m, difference: {cross_points[i].depth1 - cross_points[i].depth2:.1f}m\\ntwtt: {cross_points[i].twtt[0]:.2e} and {cross_points[i].twtt[1]:.2e}, delta_twtt: {cross_points[i].twtt[1] - cross_points[i].twtt[0]:.2e}\", fontsize=10)\n",
    "\n",
    "    plt.text(xdata[i], ydata[i] + y_label_offset, f\"cross {cross_points[i].cross_number}\\n{cross_points[i].depth_ave:.1f}m deep\\nÎtwtt {ydata[i]:.2f}ns\", fontsize=10, ha='center', va='bottom')\n",
    "\n",
    "# TODO: draw the theta and phi values for each point\n",
    "        \n",
    "# print(f\"xdata: {xdata}\")\n",
    "plt.scatter(xdata,ydata)\n",
    "\n",
    "plt.xlabel(\"|cos(Î¸) â sin(Ï)|\")\n",
    "plt.title(f\"{season} {flight} \\n|cos(Î¸) â sin(Ï)| vs delta_twtt\", fontsize=20)\n",
    "\n",
    "# get the current directory\n",
    "dir = os.getcwd()\n",
    "\n",
    "plt.ylabel(\"delta_twtt (ns)\")\n",
    "# plt.legend([\"legend\"], fontsize='smaller', loc='upper right', bbox_to_anchor=(1.1, 1.1))\n",
    "\n",
    "plt.yscale('log')\n",
    "# print(f\"abs(max(delta_twtt)): {abs(max(delta_twtt))}\")\n",
    "# set subticks to be larger\n",
    "plt.tick_params(which='major', length=10, color='black', width=2)\n",
    "plt.tick_params(which='minor', length=10, color='black', width=1)\n",
    "\n",
    "plt.xlim(-0.1, 2.1)\n",
    "\n",
    "\n",
    "plt.savefig(f\"{dir}\\\\screens\\\\{season}_{flight}_cos_angle_heading_vs_delta_twtt_logy.png\", dpi=300)\n",
    "\n",
    "\n",
    "plt.yscale('linear')\n",
    "y_min = min(ydata)\n",
    "y_max = max(ydata)\n",
    "zero = 0.000000000000000000000001  # something something floating point error\n",
    "plt.ylim(zero, y_max + y_max*.1)\n",
    "plt.xlim(-0.1, 2.1)\n",
    "plt.savefig(f\"{dir}\\\\screens\\\\{season}_{flight}_cos_angle_heading_vs_delta_twtt_lineary.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"saved plot as {dir}\\\\screens\\\\{season}_{flight}_cos_angle_heading_vs_delta_twtt.png\")\n",
    "# |cos(90) - sin(90)| = 0 - 1 = 1\n",
    "# plot should peak either at 1 or 0 depending on which flight is closer to the flow vector\n",
    "    # in theory it should be around 1 but it could be 0 if coded wrong"
   ],
   "id": "f25a2814fd42c652",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# END OF RELEVANT CODE FOR TALK",
   "id": "411b9e180549373e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Using just the flow vector and plane heading. Assumes ~90Â° angle between the legs.\n",
    "\"\"\"\n",
    "\n",
    "micro = False\n",
    "print_time = True\n",
    "\n",
    "plt.figure(figsize=(24, 12), layout='constrained')\n",
    "xdata = []\n",
    "ydata = []\n",
    "\n",
    "for i in range(len(cross_points)):\n",
    "    if math.isnan(cross_points[i].delta_twtt):\n",
    "        debug_print(f\"skipping index {i} because delta_twtt is nan\")\n",
    "        continue\n",
    "    theta = cross_points[i].angle  # plane to flow\n",
    "    phi = abs(cross_points[i].plane_heading_1 - cross_points[i].plane_heading_2)  # plane to plane\n",
    "    delta_twtt_micros = cross_points[i].delta_twtt * 1e6\n",
    "    delta_twtt_ns = cross_points[i].delta_twtt * 1e9\n",
    "        \n",
    "    # xdata = np.append(xdata, np.abs(np.cos(np.radians(theta)) - np.sin(np.radians(phi))))  # |cos(Î¸) â sin(Ï)|\n",
    "    \n",
    "    xdata = np.append(xdata, np.abs(np.cos(np.radians(theta))))  # |cos(Î¸)|\n",
    "    \n",
    "    \n",
    "    if micro:    \n",
    "        delta_twtt_unit = delta_twtt_micros  # delta_twtt (Âµs)\n",
    "        if print_time: \n",
    "            print(\"Using microseconds\")\n",
    "            print_time = False\n",
    "    else:\n",
    "        delta_twtt_unit = delta_twtt_ns  # delta_twtt (ns)\n",
    "        if print_time: \n",
    "            print(\"Using nanoseconds\")\n",
    "            print_time = False\n",
    "            \n",
    "    ydata = np.append(ydata, delta_twtt_unit)\n",
    "\n",
    "temp_twtt_s = 0\n",
    "temp_twtt_ns = 0\n",
    "y_label_offset = max(ydata) * .01\n",
    "for i in range(len(xdata)):\n",
    "    if math.isnan(xdata[i]):\n",
    "        debug_print(f\"skipping index {i} because xdata is nan\")\n",
    "        continue\n",
    "    if math.isnan(ydata[i]):\n",
    "        debug_print(f\"skipping index {i} because ydata is nan\")\n",
    "        continue\n",
    "    # plt.text(xdata[index], ydata[index] + y_label_offset, f\"Cross {index+1}: {depth[index]:.1f}m\", fontsize=10)\n",
    "    # plt.text(xdata[i], ydata[i] + y_label_offset, f\"Cross {cross_points[i].cross_number}: {cross_points[i].depth1:.1f}m and {cross_points[i].depth2:.1f}m, difference: {cross_points[i].depth1 - cross_points[i].depth2:.1f}m\\ntwtt: {cross_points[i].twtt[0]:.2e} and {cross_points[i].twtt[1]:.2e}, delta_twtt: {cross_points[i].twtt[1] - cross_points[i].twtt[0]:.2e}\", fontsize=10)\n",
    "\n",
    "    plt.text(xdata[i], ydata[i] + y_label_offset, f\"cross {cross_points[i].cross_number}\\n{cross_points[i].depth_ave:.1f}m deep\\nÎtwtt {ydata[i]:.2f}ns\", fontsize=10, ha='center', va='bottom')\n",
    "\n",
    "# TODO: draw the theta and phi values for each point\n",
    "        \n",
    "# print(f\"xdata: {xdata}\")\n",
    "plt.scatter(xdata,ydata)\n",
    "\n",
    "plt.xlabel(\"|cos(Î¸) â sin(Ï)|\")\n",
    "plt.title(f\"{season} {flight} \\n|cos(Î¸) â sin(Ï)| vs delta_twtt\", fontsize=20)\n",
    "\n",
    "# get the current directory\n",
    "dir = os.getcwd()\n",
    "\n",
    "plt.ylabel(\"delta_twtt (ns)\")\n",
    "# plt.legend([\"legend\"], fontsize='smaller', loc='upper right', bbox_to_anchor=(1.1, 1.1))\n",
    "\n",
    "plt.yscale('log')\n",
    "# print(f\"abs(max(delta_twtt)): {abs(max(delta_twtt))}\")\n",
    "# set subticks to be larger\n",
    "plt.tick_params(which='major', length=10, color='black', width=2)\n",
    "plt.tick_params(which='minor', length=10, color='black', width=1)\n",
    "\n",
    "\n",
    "plt.xlim(-0.1, 2.1)\n",
    "\n",
    "\n",
    "plt.savefig(f\"{dir}\\\\screens\\\\{season}_{flight}_cos_angle_heading-sin_angle_flow_vs_delta_twtt_logy.png\", dpi=300)\n",
    "\n",
    "\n",
    "plt.yscale('linear')\n",
    "y_min = min(ydata)\n",
    "y_max = max(ydata)\n",
    "zero = 0.000000000000000000000001  # something something floating point error\n",
    "plt.ylim(zero, y_max + y_max*.1)\n",
    "plt.xlim(-0.1, 2.1)\n",
    "plt.savefig(f\"{dir}\\\\screens\\\\{season}_{flight}_cos_angle_heading-sin_angle_flow_vs_delta_twtt_liny.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"saved plot as {dir}\\\\screens\\\\{season}_{flight}_cos_angle_heading-sin_angle_flow_vs_delta_twtt.png\")\n",
    "# |cos(90) - sin(90)| = 0 - 1 = 1\n",
    "# plot should peak either at 1 or 0 depending on which flight is closer to the flow vector\n",
    "    # in theory it should be around 1 but it could be 0 if coded wrong"
   ],
   "id": "19c16439276c5442",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "badf090b00f56021",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b12eba24a1a45650",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
