{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-11T00:14:42.166977Z",
     "start_time": "2024-07-11T00:14:41.134024Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from project_classes import *\n",
    "from functions import *\n",
    "# from iceflow_library import *\n",
    "# import scipy.optimize as optimize\n",
    "# from scipy.optimize import curve_fit\n",
    "print(\"Imports successful.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T00:14:42.976818Z",
     "start_time": "2024-07-11T00:14:42.972603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "zoom = True\n",
    "seg_length = 250\n",
    "# season = \"2009_Antarctica_DC8\"\n",
    "# season1 = \"2018_Antarctica_DC8\" \n",
    "# season2 = \"2018_Antarctica_DC8\" \n",
    "# season1 = \"2016_Antarctica_DC8\" \n",
    "# season2 = \"2016_Antarctica_DC8\" \n",
    "# season = \"2014_Antarctica_DC8\" \n",
    "season1 = \"2022_Antarctica_BaslerMKB\"\n",
    "# season2 = \"2022_Antarctica_BaslerMKB\"\n",
    "# season1 = \"2013_Antarctica_P3\"\n",
    "# flight = \"20181030_01\"  # the flight date and frame number \n",
    "    # that flight only has one point\n",
    "# flight = \"20181018_01\"\n",
    "# flight = \"20181103_01\"\n",
    "# flight1 = \"20181011_01\"\n",
    "    # one dimensional data error\n",
    "    # TODO: figure out why 10018 and 1103 have the same data or at least print the same maps and plots\n",
    "# flight = \"20181109_01\"\n",
    "# flight = \"20181112_02\"  # the problem flight\n",
    "    # plots fake crossovers along the curved path\n",
    "# flight = \"20161024_05\"\n",
    "# flight1 = \"20161015_06\"\n",
    "# flight2 = \"20161115_03\"\n",
    "    # probably too close to the coast to be useful\n",
    "# flight = \"20161024_05\"\n",
    "# flight = '20141026_06'\n",
    "\n",
    "# flight1 = \"20230108_01\"\n",
    "# flight2 = \"20230109_01\"\n",
    "    # ~ 1/3 of an orbit of the pole and yet the angle plot looks like hot garbage\n",
    "# file_name = \"layer_export_\" + flight + \".pickle\"\n",
    "# file_name1 = \"C:\\\\Users\\\\moser\\\\Desktop\\\\cresis_project\\\\pickle_jar\\\\layer_export_\" + flight1 + \".pickle\"\n",
    "# file_name2 = \"C:\\\\Users\\\\moser\\\\Desktop\\\\cresis_project\\\\pickle_jar\\\\layer_export_\" + flight2 + \".pickle\"\n",
    "testing = False"
   ],
   "id": "5a77c79d4ba30b55",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T00:18:09.722469Z",
     "start_time": "2024-07-11T00:18:09.720236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# read in the layers from the layer files and save them to a pickle file\n",
    "\n"
   ],
   "id": "f72cdc9d4c3c9c5f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T00:18:10.172405Z",
     "start_time": "2024-07-11T00:18:10.165442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def append_layers(layers1, layers2):\n",
    "    \"\"\"\n",
    "    :param layers1: a layer object\n",
    "    :param layers2: a layer object\n",
    "    :return: a combined layer object\n",
    "    \"\"\"\n",
    "    print(\"Appending layers...\")\n",
    "    print(\"--------------------\")\n",
    "    # append layers2 to layers1\n",
    "    # layers1 and layers2 have lists of layers. append each list with a given name to the other list with the same name if it exists. if it does not exist, throw an error\n",
    "    layers = []\n",
    "    layer_names = []\n",
    "    elevation = np.array([])\n",
    "    gps_time = np.array([])\n",
    "    id = np.array([])\n",
    "    lat = np.array([])\n",
    "    lon = np.array([])\n",
    "    param = np.array([])\n",
    "    quality = np.array([])\n",
    "    twtt = np.array([])\n",
    "    # layer_type = np.array([])\n",
    "    \n",
    "    for layer in layers1:\n",
    "        layer_names.append(layer.layer_name)\n",
    "        elevation = np.append(elevation, layer.elevation)\n",
    "        gps_time = np.append(gps_time, layer.gps_time)\n",
    "        id = np.append(id, layer.id)\n",
    "        lat = np.append(lat, layer.lat)\n",
    "        lon = np.append(lon, layer.lon)\n",
    "        param = np.append(param, layer.param)\n",
    "        quality = np.append(quality, layer.quality)\n",
    "        twtt = np.append(twtt, layer.twtt)\n",
    "        # layer_type = np.append(layer_type, layer.layer_type)\n",
    "    for layer in layers2:\n",
    "        if layer.layer_name in layer_names:\n",
    "            index = layer_names.index(layer.layer_name)\n",
    "            layers1[index].elevation = np.append(layers1[index].elevation, layer.elevation)\n",
    "            layers1[index].gps_time = np.append(layers1[index].gps_time, layer.gps_time)\n",
    "            layers1[index].id = np.append(layers1[index].id, layer.id)\n",
    "            layers1[index].lat = np.append(layers1[index].lat, layer.lat)\n",
    "            layers1[index].lon = np.append(layers1[index].lon, layer.lon)\n",
    "            layers1[index].param = np.append(layers1[index].param, layer.param)\n",
    "            layers1[index].quality = np.append(layers1[index].quality, layer.quality)\n",
    "            layers1[index].twtt = np.append(layers1[index].twtt, layer.twtt)\n",
    "            # layers1[index].layer_type = np.append(layers1[index].layer_type, layer.layer_type)\n",
    "        else:\n",
    "            layers1.append(layer)\n",
    "    return layers1\n"
   ],
   "id": "421aa0ec22adc55a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T00:18:13.696616Z",
     "start_time": "2024-07-11T00:18:13.693233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print(len(layers1[0].twtt))\n",
    "# print(len(layers2[0].twtt))\n",
    "# print(len(layers1[0].twtt) + len(layers2[0].twtt))\n",
    "# layers1 = append_layers(layers1, layers2)\n",
    "# print(len(layers1[0].twtt))\n",
    "\n",
    "# print(layers1)"
   ],
   "id": "8d8149dedd927841",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T00:18:23.138077Z",
     "start_time": "2024-07-11T00:18:22.892328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dir = \"C:\\\\Users\\\\moser\\\\Documents\\\\cresis\\\\rds\\\\\" + season1 + \"\\\\CSARP_layer\"\n",
    "# print(f\"dir: {dir}\")\n",
    "folders = os.listdir(dir)\n",
    "\n",
    "\n",
    "layers = []\n",
    "# print(f\"flight1: \\t{flight1}\")\n",
    "# print(f\"folders1:\\t{folders[1]}\")\n",
    "for folder in folders:\n",
    "    # print(\"folder: \", folder)\n",
    "    borked = mat_pickler_h5py(season1, folder, testing_mode=testing)  # make it\n",
    "    if borked:\n",
    "        debug_print(BRIGHT_RED, f\"Folder {folder} is borked. Skipping it.\")\n",
    "        borked = False\n",
    "        continue        \n",
    "    else:\n",
    "        print(f\"folder: {folder}\")\n",
    "        layer = read_layers(\"C:\\\\Users\\\\moser\\\\Desktop\\\\cresis_project\\\\pickle_jar\\\\layer_export_\" + folder + \".pickle\")\n",
    "        # print(f\"layer: {layer}\")\n",
    "        # print(f\"lat shape: {np.shape(layer[0].lat)}\")\n",
    "        # debug_print(f\"layer: {layer}\")\n",
    "        # print the shape of the lat-lon arrays\n",
    "        # debug_print(BRIGHT_YELLOW, f\"lat shape: {np.shape(layer[0].lat)}\")\n",
    "    layers = append_layers(layers, layer)\n",
    "    print(f\"size of lon: {len(layer[0].lon)}\")\n"
   ],
   "id": "39ec426a31af3fd4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data files...\n",
      "--------------------\n",
      "--------------------\n",
      "folder: 20221229_01\n",
      "Reading pickle file...\n",
      "--------------------\n",
      "Surface\n",
      "Bottom\n",
      "--------------------\n",
      "\n",
      "Appending layers...\n",
      "--------------------\n",
      "size of lon: 28\n",
      "Reading data files...\n",
      "--------------------\n",
      "--------------------\n",
      "folder: 20230106_01\n",
      "Reading pickle file...\n",
      "--------------------\n",
      "Surface\n",
      "Bottom\n",
      "--------------------\n",
      "\n",
      "Appending layers...\n",
      "--------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (28, 1) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 24\u001B[0m\n\u001B[0;32m     18\u001B[0m     layer \u001B[38;5;241m=\u001B[39m read_layers(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mC:\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mUsers\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mmoser\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mDesktop\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mcresis_project\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mpickle_jar\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124mlayer_export_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m folder \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.pickle\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;66;03m# print(f\"layer: {layer}\")\u001B[39;00m\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;66;03m# print(f\"lat shape: {np.shape(layer[0].lat)}\")\u001B[39;00m\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;66;03m# debug_print(f\"layer: {layer}\")\u001B[39;00m\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;66;03m# print the shape of the lat-lon arrays\u001B[39;00m\n\u001B[0;32m     23\u001B[0m     \u001B[38;5;66;03m# debug_print(BRIGHT_YELLOW, f\"lat shape: {np.shape(layer[0].lat)}\")\u001B[39;00m\n\u001B[1;32m---> 24\u001B[0m layers \u001B[38;5;241m=\u001B[39m \u001B[43mappend_layers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlayers\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlayer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msize of lon: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(layer[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mlon)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[7], line 28\u001B[0m, in \u001B[0;36mappend_layers\u001B[1;34m(layers1, layers2)\u001B[0m\n\u001B[0;32m     26\u001B[0m gps_time \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mappend(gps_time, layer\u001B[38;5;241m.\u001B[39mgps_time)\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28mid\u001B[39m \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28mid\u001B[39m, layer\u001B[38;5;241m.\u001B[39mid)\n\u001B[1;32m---> 28\u001B[0m lat \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mappend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlayer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlat\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     29\u001B[0m lon \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mappend(lon, layer\u001B[38;5;241m.\u001B[39mlon)\n\u001B[0;32m     30\u001B[0m param \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mappend(param, layer\u001B[38;5;241m.\u001B[39mparam)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\function_base.py:5616\u001B[0m, in \u001B[0;36mappend\u001B[1;34m(arr, values, axis)\u001B[0m\n\u001B[0;32m   5614\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   5615\u001B[0m         arr \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mravel()\n\u001B[1;32m-> 5616\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[43mravel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   5617\u001B[0m     axis \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mndim\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   5618\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m concatenate((arr, values), axis\u001B[38;5;241m=\u001B[39maxis)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:1874\u001B[0m, in \u001B[0;36mravel\u001B[1;34m(a, order)\u001B[0m\n\u001B[0;32m   1872\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m asarray(a)\u001B[38;5;241m.\u001B[39mravel(order\u001B[38;5;241m=\u001B[39morder)\n\u001B[0;32m   1873\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1874\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43masanyarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mravel(order\u001B[38;5;241m=\u001B[39morder)\n",
      "\u001B[1;31mValueError\u001B[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (28, 1) + inhomogeneous part."
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "afcddb3d7fdb6b14"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
